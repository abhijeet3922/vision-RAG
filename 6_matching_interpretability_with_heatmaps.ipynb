{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhijeet3922/vision-RAG/blob/main/6_matching_interpretability_with_heatmaps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretability by superimposing the late interaction heatmap on original image"
      ],
      "metadata": {
        "id": "H-WMrugqGKLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook describes interpretzbility aspect of colpali model to understand how and why the model makes specific predictions.\n",
        "\n",
        "We can visulaize image patches matching to each uery term by superimposing the late interaction heatmap on original image."
      ],
      "metadata": {
        "id": "M0PW91RgpgaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To demostrate interpretability, we perform following steps:\n",
        "\n",
        "* Create image and query embeddings.\n",
        "* Get similarity maps using API provided by colpali-engine\n",
        "* Plot maps"
      ],
      "metadata": {
        "id": "5NE4SH_5rZIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acknowledgement\n",
        "\n",
        "This notebook uses code or ideas from the following github repository:\n",
        "https://github.com/illuin-tech/colpali"
      ],
      "metadata": {
        "id": "FRqrTUk_skeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installations & imports"
      ],
      "metadata": {
        "id": "1tlJL1lUs_Xm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krobjQyvB-md",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install pdf2image\n",
        "!pip install colpali-engine[interpretability]\n",
        "!sudo apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from pdf2image import convert_from_path\n",
        "from torch.utils.data import DataLoader\n",
        "from colpali_engine.models import ColPali, ColPaliProcessor\n",
        "from colpali_engine.interpretability import (\n",
        "    get_similarity_maps_from_embeddings,\n",
        "    plot_all_similarity_maps,)"
      ],
      "metadata": {
        "id": "OpHamAeMCMXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model"
      ],
      "metadata": {
        "id": "Kq960VbYtGXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"vidore/colpali-v1.3\"\n",
        "model = ColPali.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",  # or \"mps\" if on Apple Silicon\n",
        ").eval()\n",
        "processor = ColPaliProcessor.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "_MXIKhOSCMfb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process document, identify page to visulaize."
      ],
      "metadata": {
        "id": "i0gezPw4tJI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = convert_from_path(\"/content/google-alphabet-2024.pdf\")\n",
        "print(\"Number of pages:\", len(images))"
      ],
      "metadata": {
        "id": "s5co24h6CMjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = images[10]"
      ],
      "metadata": {
        "id": "jMyJY194n6pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = [\"Revenue Google Cloud 2023 and 2024 ?\"]\n",
        "query[0]"
      ],
      "metadata": {
        "id": "bCuqlMfzCxws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process image and query using colpali"
      ],
      "metadata": {
        "id": "JMEjU2hqtQVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_images = processor.process_images([image]).to(model.device)\n",
        "batch_queries = processor.process_queries(query[0]).to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  image_embeddings = model.forward(**batch_images)\n",
        "  query_embeddings = model.forward(**batch_queries)"
      ],
      "metadata": {
        "id": "J85cfc1pLykA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of image patches\n",
        "n_patches = processor.get_n_patches(image_size=image.size, patch_size=model.patch_size)\n",
        "# Get the tensor mask to filter out the embeddings that are not related to the image\n",
        "image_mask = processor.get_image_mask(batch_images)"
      ],
      "metadata": {
        "id": "59P_ISf2C7Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_embeddings.shape, image_embeddings.shape"
      ],
      "metadata": {
        "id": "QR24OaDyM-Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the similarity maps\n",
        "batched_similarity_maps = get_similarity_maps_from_embeddings(\n",
        "    image_embeddings=image_embeddings,\n",
        "    query_embeddings=query_embeddings,\n",
        "    n_patches=n_patches,\n",
        "    image_mask=image_mask,\n",
        ")"
      ],
      "metadata": {
        "id": "vPGPKnLUHwoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the similarity map for our (only) input image\n",
        "similarity_maps = batched_similarity_maps[0]  # (query_length, n_patches_x, n_patches_y)\n",
        "# Tokenize the query\n",
        "query_tokens = processor.tokenizer.tokenize(query[0])\n"
      ],
      "metadata": {
        "id": "JehIyrotHwsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_maps.shape, len(query_tokens)"
      ],
      "metadata": {
        "id": "EM217u1S5yng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot similarity maps"
      ],
      "metadata": {
        "id": "xcFJKxsttnFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot and save the similarity maps for each query token\n",
        "plots = plot_all_similarity_maps(\n",
        "    image=image,\n",
        "    query_tokens=query_tokens,\n",
        "    similarity_maps=similarity_maps,\n",
        ")\n",
        "#for idx, (fig, ax) in enumerate(plots):\n",
        "#    fig.savefig(f\"similarity_map_{idx}.png\")"
      ],
      "metadata": {
        "id": "KS7q16zhH1lK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}